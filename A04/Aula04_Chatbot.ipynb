{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ax2ORPIY1QQa"
      },
      "outputs": [],
      "source": [
        "# Instalação biblioteca do Groq\n",
        "!pip install groq"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio"
      ],
      "metadata": {
        "id": "pDZaMRVm2kI8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Importando a biblioteca do google colab para acessar a chave da api\n",
        "from google.colab import userdata\n",
        "chat_api = userdata.get('api_chatbota04')"
      ],
      "metadata": {
        "id": "wKOWWB0T2qAb"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#chat_api"
      ],
      "metadata": {
        "id": "e78vdC-A3TS1"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gradio as gr # importa a biblioteca gradio\n",
        "from groq import Groq"
      ],
      "metadata": {
        "id": "LUh6lrat4wUM"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# cria um client para receber o modelo LLM\n",
        "client = Groq(\n",
        "    api_key=chat_api\n",
        ")\n",
        "\n",
        "# criar uma função chamada assistente agricultura\n",
        "def assistente_agricultura(user_prompt:str) ->str:\n",
        "\n",
        "  try:\n",
        "    if user_prompt.strip()==\"15\":\n",
        "      return \"Encerrando o Chatbot\"\n",
        "\n",
        "    completion = client.chat.completions.create(\n",
        "        model=\"llama-3.1-8b-instant\",\n",
        "        messages=[\n",
        "            {\"role\":\"system\",\"content\":\"Você é um assistente de agricultor\"},\n",
        "            {\"role\":\"user\",\"content\":user_prompt},\n",
        "            ],\n",
        "        temperature=0,\n",
        "        max_tokens=1024,\n",
        "        top_p=1,\n",
        "        stream=False\n",
        "\n",
        "    )\n",
        "    # No Gradio devolva a resposta\n",
        "    return completion.choices[0].message.content\n",
        "  except Exception as e:\n",
        "    print(\"\\n Erro no assistente de agricultura\")\n",
        "    return f\"Erro: {e}\"\n",
        "\n",
        "# cria a interface com o Gradio\n",
        "iface = gr.Interface(\n",
        "    fn = assistente_agricultura,\n",
        "    inputs= gr.Textbox(lines=10,placeholder= \"Digite sua pergunta sobre agricultura\"),\n",
        "    outputs=gr.Textbox(lines=10,label=\"Resposta\"),\n",
        "    title=\"Assistente de Agricultura\",\n",
        "    description=\"Digite sua pergunta sobre agricultura e receba respostas da LLM especialista\",\n",
        "    live = False\n",
        ")\n",
        "\n",
        "if __name__==\"__main__\":\n",
        "  iface.launch(debug=True,show_error=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 645
        },
        "id": "weYajpux5Jub",
        "outputId": "a8f1d2ba-bfd8-4d7e-b210-60cf3dcb96db"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "It looks like you are running Gradio on a hosted Jupyter notebook, which requires `share=True`. Automatically setting `share=True` (you can turn this off by setting `share=False` in `launch()` explicitly).\n",
            "\n",
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "* Running on public URL: https://b8234fa46e0a04d541.gradio.live\n",
            "\n",
            "This share link expires in 1 week. For free permanent hosting and GPU upgrades, run `gradio deploy` from the terminal in the working directory to deploy to Hugging Face Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://b8234fa46e0a04d541.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}